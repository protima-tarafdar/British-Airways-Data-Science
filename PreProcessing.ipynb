{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "reviews = []\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  Good domestic flight operat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified | Failed at all basic travel fund...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  They lost my baggage in a v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |  Late boarding led to a one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified | As usual the flight is delay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews\n",
       "0  ✅ Trip Verified |  Good domestic flight operat...\n",
       "1  Not Verified | Failed at all basic travel fund...\n",
       "2  ✅ Trip Verified |  They lost my baggage in a v...\n",
       "3  ✅ Trip Verified |  Late boarding led to a one ...\n",
       "4  ✅ Trip Verified | As usual the flight is delay..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/protimatarafdar/Downloads/BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reviews= df.reviews.str.split('|',expand=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good domestic flight operated by BA Cityflye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Failed at all basic travel fundamentals: 1) O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>They lost my baggage in a very simple situat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Late boarding led to a one hour flight leavi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As usual the flight is delayed. BA try to bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Miami to London Heathrow. As with many other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>London Heathrow to Milan Malpensa. Worst airl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Calgary to Rome via London. My wife and I bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>London to Bangkok. Flew British Airways for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>London Heathrow to Miami. The airport staff ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0      Good domestic flight operated by BA Cityflye...\n",
       "1     Failed at all basic travel fundamentals: 1) O...\n",
       "2      They lost my baggage in a very simple situat...\n",
       "3      Late boarding led to a one hour flight leavi...\n",
       "4     As usual the flight is delayed. BA try to bla...\n",
       "..                                                 ...\n",
       "995    Miami to London Heathrow. As with many other...\n",
       "996   London Heathrow to Milan Malpensa. Worst airl...\n",
       "997    Calgary to Rome via London. My wife and I bo...\n",
       "998    London to Bangkok. Flew British Airways for ...\n",
       "999    London Heathrow to Miami. The airport staff ...\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Text Preprocessing\n",
    "\n",
    "--\n",
    "\n",
    "##Removed punctuations, emojis, lower case, and then tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 8] nodename\n",
      "[nltk_data]     nor servname provided, or not known>\n",
      "[nltk_data] Error loading punkt: <urlopen error [Errno 8] nodename nor\n",
      "[nltk_data]     servname provided, or not known>\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Function to clean a single review\n",
    "def clean_review(review):\n",
    "    # Convert to lowercase\n",
    "    review = review.lower()\n",
    "    \n",
    "    # Remove punctuation\n",
    "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    #Remove Special Characters\n",
    "    review = re.sub(r'[^a-zA-Z0-9\\s]', '', review)\n",
    "\n",
    "    #Remove numbers\n",
    "    review = ''.join([c for c in review if not c.isdigit()])\n",
    "   \n",
    "    # Tokenize the review\n",
    "    words = word_tokenize(review)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    additional_stopwords = ['british', 'airways', 'ba', \"flight\", 'london']\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    custom_stopwords = stop_words.union(additional_stopwords)\n",
    "    words = [word for word in words if word not in custom_stopwords]\n",
    "\n",
    "    # Join the cleaned words back to a sentence\n",
    "    cleaned_review = ' '.join(words)\n",
    "    \n",
    "    return cleaned_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files: '/Users/protimatarafdar/nltk_data/corpora/stopwords/english'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/protimatarafdar/Downloads/getting_started.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mcleaned_reviews\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mreviews\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(clean_review)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1138\u001b[0m             values,\n\u001b[1;32m   1139\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1141\u001b[0m         )\n\u001b[1;32m   1143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/protimatarafdar/Downloads/getting_started.ipynb Cell 11\u001b[0m in \u001b[0;36mclean_review\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Remove stopwords\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m additional_stopwords \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbritish\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mairways\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mba\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mflight\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlondon\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m stop_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39;49mwords(\u001b[39m'\u001b[39;49m\u001b[39menglish\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X26sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m custom_stopwords \u001b[39m=\u001b[39m stop_words\u001b[39m.\u001b[39munion(additional_stopwords)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X26sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m words \u001b[39m=\u001b[39m [word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m words \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m custom_stopwords]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/reader/wordlist.py:21\u001b[0m, in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/reader/api.py:218\u001b[0m, in \u001b[0;36mraw\u001b[0;34m(self, fileids)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/corpus/reader/api.py:231\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(self, file)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/nltk/data.py:324\u001b[0m, in \u001b[0;36mFileSystemPathPointer.open\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 324\u001b[0m     stream \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_path, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    325\u001b[0m     \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m         stream \u001b[39m=\u001b[39m SeekableUnicodeStreamReader(stream, encoding)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 24] Too many open files: '/Users/protimatarafdar/nltk_data/corpora/stopwords/english'"
     ]
    }
   ],
   "source": [
    "df['cleaned_reviews'] = df['reviews'].apply(clean_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good domestic flight operated by ba cityflye...</td>\n",
       "      <td>good domestic operated cityflyer ground servic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failed at all basic travel fundamentals: 1) o...</td>\n",
       "      <td>failed basic travel fundamentals delayed staff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they lost my baggage in a very simple situat...</td>\n",
       "      <td>lost baggage simple situation three weeks dont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>late boarding led to a one hour flight leavi...</td>\n",
       "      <td>late boarding led one hour leaving two hours l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>as usual the flight is delayed. ba try to bla...</td>\n",
       "      <td>usual delayed try blame someone inability inca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0    good domestic flight operated by ba cityflye...   \n",
       "1   failed at all basic travel fundamentals: 1) o...   \n",
       "2    they lost my baggage in a very simple situat...   \n",
       "3    late boarding led to a one hour flight leavi...   \n",
       "4   as usual the flight is delayed. ba try to bla...   \n",
       "\n",
       "                                     cleaned_reviews  \n",
       "0  good domestic operated cityflyer ground servic...  \n",
       "1  failed basic travel fundamentals delayed staff...  \n",
       "2  lost baggage simple situation three weeks dont...  \n",
       "3  late boarding led one hour leaving two hours l...  \n",
       "4  usual delayed try blame someone inability inca...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Data Analysis - Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['cleaned_reviews'].tolist()\n",
    "\n",
    "# Tokenize and remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokenized_reviews = [word_tokenize(review) for review in reviews]\n",
    "tokenized_reviews = [[word for word in review if word not in stop_words] for review in tokenized_reviews]\n",
    "\n",
    "# Create a dictionary and a corpus\n",
    "dictionary = corpora.Dictionary(tokenized_reviews)\n",
    "corpus = [dictionary.doc2bow(review) for review in tokenized_reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics\n",
    "num_topics = 15\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.014*\"service\"\n",
      "Topic 2: 0.014*\"good\"\n",
      "Topic 3: 0.012*\"seat\"\n",
      "Topic 4: 0.012*\"us\"\n",
      "Topic 5: 0.030*\"seat\"\n",
      "Topic 6: 0.015*\"seats\"\n",
      "Topic 7: 0.011*\"seat\"\n",
      "Topic 8: 0.010*\"service\"\n",
      "Topic 9: 0.010*\"crew\"\n",
      "Topic 10: 0.015*\"cabin\"\n",
      "Topic 11: 0.009*\"food\"\n",
      "Topic 12: 0.010*\"class\"\n",
      "Topic 13: 0.007*\"booked\"\n",
      "Topic 14: 0.017*\"crew\"\n",
      "Topic 15: 0.008*\"time\"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print topics and their associated words\n",
    "topics = lda_model.print_topics(num_words=1)\n",
    "for i, topic in enumerate(topics):\n",
    "    print(f\"Topic {i + 1}: {topic[1]}\")\n",
    "\n",
    "# Extract topic frequencies from the corpus\n",
    "topic_frequencies = [dict(topic_dist) for topic_dist in lda_model.get_document_topics(corpus)]\n",
    "\n",
    "# Create a DataFrame for topic frequencies\n",
    "topic_df = pd.DataFrame(topic_frequencies)\n",
    "topic_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "# Calculate the sum of topic frequencies\n",
    "topic_sum = topic_df.sum().sort_values(ascending=False)\n",
    "\n",
    "# Create a bar plot using matplotlib\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(topic_sum.index, topic_sum.values)\n",
    "plt.xlabel('Topics')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Topic Frequencies')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files: '/Users/protimatarafdar/Desktop/s.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/protimatarafdar/Downloads/getting_started.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/protimatarafdar/Desktop/s.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3540\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3542\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3543\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3544\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3549\u001b[0m )\n\u001b[0;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3552\u001b[0m     path_or_buf,\n\u001b[1;32m   3553\u001b[0m     line_terminator\u001b[39m=\u001b[39;49mline_terminator,\n\u001b[1;32m   3554\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3555\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3556\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3557\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3558\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3559\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3560\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3561\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3562\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3563\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3564\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3565\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3566\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3567\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3568\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[39m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    790\u001b[0m             handle,\n\u001b[1;32m    791\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    792\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    793\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    794\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    795\u001b[0m         )\n\u001b[1;32m    796\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 24] Too many open files: '/Users/protimatarafdar/Desktop/s.csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv(\"/Users/protimatarafdar/Desktop/s.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: '/Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages/pytagcloud/fonts/Lobster.ttf'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/protimatarafdar/Downloads/getting_started.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X46sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m tags \u001b[39m=\u001b[39m make_tags(\u001b[39mlist\u001b[39m(word_counts\u001b[39m.\u001b[39mitems()), maxsize\u001b[39m=\u001b[39m\u001b[39m80\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X46sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Create a word cloud image\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X46sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m create_tag_image(tags, \u001b[39m'\u001b[39;49m\u001b[39mwordcloud.png\u001b[39;49m\u001b[39m'\u001b[39;49m, size\u001b[39m=\u001b[39;49m(\u001b[39m800\u001b[39;49m, \u001b[39m400\u001b[39;49m), fontname\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mLobster\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X46sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Display the word cloud image using matplotlib\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X46sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytagcloud/__init__.py:340\u001b[0m, in \u001b[0;36mcreate_tag_image\u001b[0;34m(tags, output, size, background, layout, fontname, rectangular)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(tags):\n\u001b[1;32m    338\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 340\u001b[0m sizeRect, tag_store \u001b[39m=\u001b[39m _draw_cloud(tags,\n\u001b[1;32m    341\u001b[0m                                   layout,\n\u001b[1;32m    342\u001b[0m                                   size\u001b[39m=\u001b[39;49msize, \n\u001b[1;32m    343\u001b[0m                                   fontname\u001b[39m=\u001b[39;49mfontname,\n\u001b[1;32m    344\u001b[0m                                   rectangular\u001b[39m=\u001b[39;49mrectangular)\n\u001b[1;32m    346\u001b[0m image_surface \u001b[39m=\u001b[39m Surface((sizeRect\u001b[39m.\u001b[39mw, sizeRect\u001b[39m.\u001b[39mh), SRCALPHA, \u001b[39m32\u001b[39m)\n\u001b[1;32m    347\u001b[0m image_surface\u001b[39m.\u001b[39mfill(background)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytagcloud/__init__.py:275\u001b[0m, in \u001b[0;36m_draw_cloud\u001b[0;34m(tag_list, layout, size, fontname, rectangular)\u001b[0m\n\u001b[1;32m    273\u001b[0m area \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    274\u001b[0m \u001b[39mfor\u001b[39;00m tag \u001b[39min\u001b[39;00m tag_list:\n\u001b[0;32m--> 275\u001b[0m     tag_sprite \u001b[39m=\u001b[39m Tag(tag, (\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m), fontname\u001b[39m=\u001b[39;49mfontname)\n\u001b[1;32m    276\u001b[0m     area \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tag_sprite\u001b[39m.\u001b[39mmask\u001b[39m.\u001b[39mcount()\n\u001b[1;32m    277\u001b[0m     tag_sprites\u001b[39m.\u001b[39mappend(tag_sprite)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pytagcloud/__init__.py:60\u001b[0m, in \u001b[0;36mTag.__init__\u001b[0;34m(self, tag, initial_position, fontname)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrotation \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfont_spec \u001b[39m=\u001b[39m load_font(fontname)\n\u001b[0;32m---> 60\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfont \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39;49mFont(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(FONT_DIR,\n\u001b[1;32m     61\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfont_spec[\u001b[39m'\u001b[39;49m\u001b[39mttf\u001b[39;49m\u001b[39m'\u001b[39;49m]),\n\u001b[1;32m     62\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtag[\u001b[39m'\u001b[39;49m\u001b[39msize\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     63\u001b[0m fonter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfont\u001b[39m.\u001b[39mrender(tag[\u001b[39m'\u001b[39m\u001b[39mtag\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mTrue\u001b[39;00m, tag[\u001b[39m'\u001b[39m\u001b[39mcolor\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     64\u001b[0m frect \u001b[39m=\u001b[39m fonter\u001b[39m.\u001b[39mget_bounding_rect()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory: '/Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages/pytagcloud/fonts/Lobster.ttf'."
     ]
    }
   ],
   "source": [
    "from pytagcloud import create_tag_image, make_tags\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Combine cleaned reviews into a single string\n",
    "all_cleaned_reviews = ' '.join(df['cleaned_reviews'])\n",
    "\n",
    "#Split cleaned reviews into individual words\n",
    "all_cleaned_reviews_words = all_cleaned_reviews.split()\n",
    "\n",
    "# Count the frequency of each word\n",
    "word_counts = {word: all_cleaned_reviews_words.count(word) for word in all_cleaned_reviews_words}\n",
    "\n",
    "# Create tags for word cloud\n",
    "tags = make_tags(list(word_counts.items()), maxsize=80)\n",
    "\n",
    "# Create a word cloud image\n",
    "create_tag_image(tags, 'wordcloud.png', size=(800, 400), fontname='Lobster')\n",
    "\n",
    "# Display the word cloud image using matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(plt.imread('wordcloud.png'), interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - Cleaned Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simplejson\n",
      "  Downloading simplejson-3.19.1-cp39-cp39-macosx_10_9_x86_64.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 4.6 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: simplejson\n",
      "Successfully installed simplejson-3.19.1\n"
     ]
    }
   ],
   "source": [
    "!pip install simplejson\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.25.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/protimatarafdar/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install wordcloud\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/protimatarafdar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/protimatarafdar/Downloads/getting_started.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m font_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/path/to/your/font.ttf\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# Replace with the actual font file path\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Generate a word cloud with the specified font path\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m wordcloud \u001b[39m=\u001b[39m WordCloud(width\u001b[39m=\u001b[39;49m\u001b[39m800\u001b[39;49m, height\u001b[39m=\u001b[39;49m\u001b[39m400\u001b[39;49m, background_color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mwhite\u001b[39;49m\u001b[39m'\u001b[39;49m, font_path\u001b[39m=\u001b[39;49mfont_path)\u001b[39m.\u001b[39;49mgenerate(all_cleaned_reviews)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Display the word cloud using matplotlib\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/protimatarafdar/Downloads/getting_started.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m5\u001b[39m))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m, text):\n\u001b[1;32m    625\u001b[0m     \u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \n\u001b[1;32m    627\u001b[0m \u001b[39m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39m    self\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_text(text)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[39m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[1;32m    605\u001b[0m \n\u001b[1;32m    606\u001b[0m \u001b[39mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mself\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    620\u001b[0m words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_text(text)\n\u001b[0;32m--> 621\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(words)\n\u001b[1;32m    622\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:453\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    451\u001b[0m     font_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 453\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_from_frequencies(\u001b[39mdict\u001b[39;49m(frequencies[:\u001b[39m2\u001b[39;49m]),\n\u001b[1;32m    454\u001b[0m                                    max_font_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheight)\n\u001b[1;32m    455\u001b[0m     \u001b[39m# find font sizes\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     sizes \u001b[39m=\u001b[39m [x[\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout_]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/wordcloud/wordcloud.py:503\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[0;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[1;32m    500\u001b[0m tried_other_orientation \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     \u001b[39m# try to find a position\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m     font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39;49mtruetype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfont_path, font_size)\n\u001b[1;32m    504\u001b[0m     \u001b[39m# transpose font optionally\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     transposed_font \u001b[39m=\u001b[39m ImageFont\u001b[39m.\u001b[39mTransposedFont(\n\u001b[1;32m    506\u001b[0m         font, orientation\u001b[39m=\u001b[39morientation)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/ImageFont.py:844\u001b[0m, in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[39mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[1;32m    843\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 844\u001b[0m     \u001b[39mreturn\u001b[39;00m freetype(font)\n\u001b[1;32m    845\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m isPath(font):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/ImageFont.py:841\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfreetype\u001b[39m(font):\n\u001b[0;32m--> 841\u001b[0m     \u001b[39mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/PIL/ImageFont.py:193\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 load_from_bytes(f)\n\u001b[1;32m    192\u001b[0m             \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfont \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mgetfont(\n\u001b[1;32m    194\u001b[0m         font, size, index, encoding, layout_engine\u001b[39m=\u001b[39;49mlayout_engine\n\u001b[1;32m    195\u001b[0m     )\n\u001b[1;32m    196\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     load_from_bytes(font)\n",
      "\u001b[0;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Create a single string containing all cleaned reviews\n",
    "all_cleaned_reviews = ' '.join(df['cleaned_reviews'])\n",
    "\n",
    "# Set a font path that is available on your system\n",
    "font_path = \"/path/to/your/font.ttf\"  # Replace with the actual font file path\n",
    "\n",
    "# Generate a word cloud with the specified font path\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', font_path=font_path).generate(all_cleaned_reviews)\n",
    "\n",
    "# Display the word cloud using matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
